{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering, explored with Semantic Kernel and Azure OpenAI\n",
    "\n",
    "To quickly get started, follow these steps:\n",
    "\n",
    "1. Install [Polyglot notebooks extension](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) in VSCode.\n",
    "2. [Create a new Azure OpenAI service (or use an existing OpenAI service)](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio#prerequisites).\n",
    "3. [Deploy the `gpt-35-turbo` and `text-embeddings-ada-002` models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#working-with-models).\n",
    "4. [Create an Azure Cognitive Search instance and enable the Semantic Search capability](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview#enable-semantic-search).\n",
    "5. Copy the `.env.example` file from the parent folder to `dotnet/.env` and paste the corresponding values from the resources you provisioned in the earlier steps.\n",
    "6. Click on `Run All`.\n",
    "\n",
    "\n",
    "> You will need an [.Net 7 SDK](https://dotnet.microsoft.com/en-us/download) and [Polyglot](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) to get started with this notebook using .Net Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## What is Prompt Engineering?\n",
    "Prompt engineering is an iterative approach for crafting and refining prompts to enhance interactions with Large Language Models (LLMs). Mastery of prompt engineering is key to unlocking the full potential of LLMs in various applications. This has been pivotal in achieving advanced use cases in Microsoft Copilots.\n",
    "\n",
    "This notebook serves as your go-to resource for effective prompt engineering techniques.\n",
    "\n",
    "### Best Practices: Insights from Azure OpenAI\n",
    "\n",
    "#### Be Specific and Descriptive\n",
    "Craft your prompts to be both specific and descriptive to minimize ambiguity. Using analogies or metaphors can aid in making the prompts more understandable and relatable to the model.\n",
    "\n",
    "#### Be Repetitive\n",
    "- **Repeat**: Reiterate key instructions to ensure clarity and focus in the model's output.\n",
    "- **Order Matters**: The sequence in which you present instructions can influence the model’s response due to its recency bias.\n",
    "\n",
    "#### Space Efficiency\n",
    "- **Token Limitations**: Be aware of the token limits for the model you are invoking.\n",
    "- **Data Formats**: Opt for tabular formats over JSON for greater space efficiency.\n",
    "- **White Space**: Use space judiciously, as each extra space counts as a token and can limit the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level Objectives\n",
    "1. Include\n",
    "\t> Include instructions of requesting the model not to make up stuff but stay with facts.\n",
    "1. Restrict\n",
    "\t> Restrict the output (e.g., choose from a confined list instead of generating free form strings)\n",
    "1. Add\n",
    "\t> Add Chain of Thought style of instruction, \"Solve the problem step by step.\"\n",
    "1. Repeat\n",
    "\t> Repeat most important instructions in the prompt a couple of times.\n",
    "1. Position\n",
    "\t> Position most important instructions in the last making use of latency effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started\n",
    "\n",
    "We will be utilizing **Semantic Kernel** to orchestrate interactions with the `gpt-35-turbo` model, which is deployed on **Azure OpenAI** for brevity. Alternatively, you can also use the **Azure OpenAI SDK** for model orchestration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Kernel to Interact with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>dotenv.net, 3.1.3</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: dotenv.net\"\n",
    "dotenv.net.DotEnv.Load();\n",
    "var env = dotenv.net.DotEnv.Read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.0.0-beta6</span></li><li><span>Microsoft.SemanticKernel.Connectors.Memory.AzureCognitiveSearch, 1.0.0-beta6</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.0.0-beta6\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Memory.AzureCognitiveSearch, 1.0.0-beta6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Orchestration;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Initialize the kernel using Azure OpenAI Chat completion model and memory store for RaG related prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var builder = new KernelBuilder();\n",
    "\n",
    "builder\n",
    ".WithAzureOpenAIChatCompletionService(\n",
    "    env[\"AZURE_OPENAI_CHAT_MODEL\"],\n",
    "    env[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    env[\"AZURE_OPENAI_API_KEY\"]\n",
    ");\n",
    "\n",
    "IKernel kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Plugins.Memory;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI;\n",
    "var memoryBuilder = new MemoryBuilder();\n",
    "memoryBuilder\n",
    "    .WithAzureOpenAITextEmbeddingGenerationService(\n",
    "        env[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "        env[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        env[\"AZURE_OPENAI_API_KEY\"]\n",
    "    )\n",
    "\n",
    "    .WithMemoryStore(new VolatileMemoryStore());\n",
    "\n",
    "var memory = memoryBuilder.Build();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with clear instructions\n",
    "> Tell the model the task you want it to do at the beginning of the prompt and repeat at the end \n",
    "\n",
    "It’s obvious that the we want to provide the model with clear instructions rather than vague instruction but in addition the sequence in which information is fed in the prompt, matters (GPT style models are built in a certain way and that’s the reason behind this). Our research suggests that telling the model the task you want it to do at the beginning of the prompt, before sharing additional contextual information or examples, can help produce higher-quality outputs.\n",
    "\n",
    "In this example, we give the exact statement we want to check (“Several sources mention a chance of another eruption”) before we give the snippet context. This allows the token representations extracted from the snippets to be tailored to the statement we are checking. And the resulting model response is accurate.\n",
    "\n",
    "Models can be susceptible to “recency bias,” which means that information at the end of the prompt might have more significant influence over the output than information at the beginning of the prompt. Another technique is to try repeating the instructions at the end of the prompt.\n",
    "Repeating the instruction at the beginning as well as the end of the prompt leads to a higher likelihood of getting an accurate model response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the statement \"Several sources mention a chance of another large eruption\" is not directly implied or stated by the snippets. The snippets provided discuss the probability of a large earthquake, not an eruption. An eruption typically refers to a volcanic event, which is different from an earthquake.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Your task is to verify if the statement \"Several sources mention a chance of another large eruption\" is supported by a specific quote from the following set of snippets.\n",
    "{{$input}}\n",
    "Is the statement \"Several sources mention a chance of another large eruption\" directly implied or stated by the snippets?\n",
    "\"\"\";\n",
    "\n",
    "var clearInstructionsFunction = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string input = \n",
    "        \"\"\"\n",
    "        ---\n",
    "        SNIPPETS\n",
    "        [1] 14 percent chance of megaquake hitting Seattle, experts say\n",
    "        SEATTLE - There's a 14 percent chance of a magnitude 9 Cascadia earthquake hitting Seattle in the next 50 years, the U.S. Geological Survey estimates. \"Unfortunately, we are unable to...\n",
    "        [2] Earthquake experts lay out latest outlook for Seattle's 'Really Big One’\n",
    "        “We say that there's approximately a 14% chance of another approximately magnitude-9 earthquake occurring in the next 50 years,” said Erin Wirth, a geophysicist at the University of Washington...\n",
    "        ---\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(input, clearInstructionsFunction);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime the output\n",
    "> Add phrases at the end of the prompt to obtain a model response in a desired form\n",
    "\n",
    "Another technique is to prime the output, that is add phrases at the end of the prompt to obtain a model response in a desired format.\n",
    "For example, as shown here for this particular task, it is important to \"commit\" the model to the list generation process\n",
    "This refers to including a few words or phrases at the end of the prompt to obtain a model response that follows the desired form. For example, using a cue such as “Here’s a bulleted list of key points:\\n-” can help make sure the outputted is formatted as a list of bullet points.\n",
    "\n",
    "In the above prompt, the text \"One possible search query is:\" primes the model to produce an output in the form of a search query. This technique can help remove hedges that the model might typically add, such as “One possibility is...”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Microsoft OpenAI is focused on unlocking the potential of AI to help people achieve more.\n",
      "- The platform enables developers to build intelligent applications and services.\n",
      "- The mission is to democratize AI, making it accessible and beneficial to everyone.\n",
      "- Microsoft OpenAI is committed to advancing the state of the art in AI.\n",
      "- The vision is a future where AI can be used to solve some of the world's most pressing challenges.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "The future of artificial intelligence is bright. With Microsoft OpenAI, we are unlocking the potential of AI to help people achieve more. We are creating a platform that enables developers to build intelligent applications and services that can help people in their everyday lives. Our mission is to democratize AI so that everyone can benefit from its power. We are committed to advancing the state of the art in AI and making it accessible to everyone. With Microsoft OpenAI, we are taking the first steps towards a future where AI can be used to solve some of the world's most pressing challenges.\n",
    "\n",
    "{{$input}}\n",
    "\"\"\";\n",
    "\n",
    "var primeOutputFunction = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string input = \n",
    "        \"\"\"\n",
    "        Here’s a bulleted list of key points:\\n-\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(input, primeOutputFunction);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"John Smith Microsoft software engineer\"\n",
      "Another possible search query could be: \n",
      "\"John Smith Lucy Smith marriage\"\n",
      "And another one could be:\n",
      "\"John Smith five children\"\n",
      "\n",
      "Please note that \"John Smith\" is a very common name, so you may need to add more specific details to your search if you have them, such as a location or a more specific job title. Also, personal information like this may not be publicly available or easily found online due to privacy reasons.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "John Smith is married to Lucy Smith. They have five kids, and he works as a software engineer at Microsoft. \n",
    "\n",
    "\n",
    "What search queries should I do to fact-check this?\n",
    "\n",
    "##\n",
    "\n",
    "{{$input}}\n",
    "\"\"\";\n",
    "\n",
    "var func2 = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string input = \n",
    "        \"\"\"\n",
    "        One possible search query is:\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(input, func2);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add clear syntax\n",
    "> Include punctuation, headings, and section markers to help communicate intent\n",
    "\n",
    "Using clear syntax for your prompt—including punctuation, headings, and section markers—helps communicate intent and often makes outputs easier to parse.\n",
    "In the example below, separators (“---” in this case) have been added between different sources of information or steps. This allows the use of “---” as a stopping condition for generation. In addition, section headings or special variables are presented in uppercase to differentiate them.\n",
    "\n",
    "If you’re not sure what syntax to use, consider using markdown or XML, since LLMs have been trained on a lot of web content in XML or markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fact-check the information provided in the paragraph, you could use the following search queries:\n",
      "\n",
      "1. \"John Smith software engineer Microsoft\": This query is to verify if John Smith is indeed a software engineer at Microsoft. However, it's worth noting that \"John Smith\" is a very common name, so you may need additional information to confirm this fact.\n",
      "\n",
      "2. \"John Smith Lucy Smith marriage\": This query is to confirm if John Smith is married to Lucy Smith. Again, due to the commonality of these names, additional information might be needed to confirm this fact.\n",
      "\n",
      "3. \"John Smith Lucy Smith children\": This query is to verify if John Smith and Lucy Smith have five children. \n",
      "\n",
      "Please note that these queries are based on the assumption that John Smith is a public figure or has a public presence. If he is a private individual, it's unlikely that this information would be readily available due to privacy laws and regulations.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "You will read a paragraph, and then issue queries to a search engine in order to fact-check it. Also explain the queries.\n",
    "\n",
    "---\n",
    "PARAGRAPH\n",
    "\n",
    "{{$input}}\n",
    "\n",
    "---\n",
    "\"\"\";\n",
    "\n",
    "var clearSyntax = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string input = \n",
    "        \"\"\"\n",
    "        John Smith is married to Lucy Smith. They have five kids, and he works as a software engineer at Microsoft. What search queries should I do to fact-check this?\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(input, clearSyntax);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Chaining\n",
    "\n",
    "Prompt chaining is a technique that involves concatenating several prompts to create a more complex prompt that directs the model towards specific outputs. This technique is powerful for prompt engineering because it enables the creation of a more focused prompt that provides the model with more specific information to generate an output. By chaining prompts, the model is directed to focus on specific aspects of the task or problem at hand, improving the accuracy and relevance of the generated outputs. Additionally, prompt chaining allows for the integration of diverse information sources, helping to ground the model in factual information and generate more accurate and relevant outputs. Overall, prompt chaining is a powerful technique for prompt engineering as it provides a flexible and customizable approach for directing models towards specific outputs, improving their effectiveness in a wide range of applications.\n",
    "\n",
    "> Note: Use Semantic Kernel's planner (sequential or stepwise) to chain this properly. The approach below is used to convey the technique in the simplest possible way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone, next month, Apple, larger screen, improved camera\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Please extract entities from the following news article: \n",
    "---\n",
    "'{{$input}}'\n",
    "---\n",
    "\n",
    "Only reply entities and DO NOT add anything extra\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "var summaryFunction = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string input = \n",
    "        \"\"\"\n",
    "        The new iPhone model is set to be released next month. It has been highly anticipated by Apple fans and is expected to feature a larger screen and improved camera\n",
    "        \"\"\";\n",
    "var extractEntities = await kernel.RunAsync(input, summaryFunction);\n",
    "var extractedEntities = extractEntities.GetValue<string>();\n",
    "\n",
    "Console.WriteLine(extractedEntities);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chained with Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next month, Apple is set to release a new iPhone featuring a larger screen and an improved camera.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Please summarize the information about the product:\n",
    "\n",
    "{{$input}}\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "var summaryFunction = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "var summary = await kernel.RunAsync(extractedEntities, summaryFunction);\n",
    "var summaryOutput = summary.GetValue<string>();\n",
    "\n",
    "Console.WriteLine(summaryOutput);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chained with Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Please provide a sentiment for the following text:\n",
    "\n",
    "---\n",
    "{{$input}}\n",
    "---\n",
    "\n",
    "Ony respond in one word: positive, negative, or neutral\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "var summaryFunction = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "var sentimentFunc = await kernel.RunAsync(summaryOutput, summaryFunction);\n",
    "\n",
    "Console.WriteLine( sentimentFunc.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot learning\n",
    "> Also known as in-context learning, it allows the model to interact with new knowledge\n",
    "\n",
    "We talked about few-shot before but again it is a very common way to adapt language models to new tasks is to use few-shot learning, also known as in-context learning. In few-shot learning a set of training examples is provided in the prompt and then the LLM is asked to complete one more unfinished example.\n",
    "In the following example we use an instruction combined with few-shot learning make up puns\n",
    "Choose your few-shot examples carefully and ensure they cover a variety of circumstances relevant to your scenario, including edge cases.\n",
    "Also, as shared earlier, the LLM models can exhibit a form of recency bias. This means that the order in which \"few-shot\" examples are provided to the model, matters. If you don't want this to matter, consider sampling multiple completions from prompts based on randomized orderings of the examples or list items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A sophisticated AI-ristocrat.\"\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Write a list of puns.\n",
    "\n",
    "---\n",
    "{{$input}}\n",
    "\"\"\";\n",
    "\n",
    "var clearSyntax = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string fewShotExamples = \n",
    "        \"\"\"\n",
    "        1. \"Why did Adele cross the road? To say hello from the other side.\"\n",
    "\n",
    "        2. \"What kind of concert only costs 45 cents? A 50 Cent concert featuring Nickelback.\"\n",
    "\n",
    "        3. \"What did the grape say when it got crushed? Nothing, it just let out a little wine.\"\n",
    "\n",
    "        4. \"What was Forrest Gump's email password? 1forrest1\"\n",
    "\n",
    "        5. \"Can February March? No, but April May.\"\n",
    "\n",
    "        6. \"What do you call fancy language model?\n",
    "\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(fewShotExamples, clearSyntax);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Reasoning\n",
    "\n",
    "Few-shot reasoning is similar to few-shot prompt but instead here we provide an reasoning example for a specific task to help the model reason on a different task. For example here, if ask the model to answer a simple logical reasoning task, it fails, but if we provide the model with a similar logical reasoning example , it shows the model how it can solve for a different similar logical task. Here in the example on the left , we provide the prompt with a different example that has the same logical reasoning needed to solve the problem and as a result the model understand the mechanism needed to solve for the new problem. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafeteria started with 23 apples. They used 20, so they had 23 - 20 = 3 apples left. Then they bought 6 more, so 3 + 6 = 9. The cafeteria now has 9 apples.\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "\n",
    "Answer: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5+6 = 11. The answer is 11. \n",
    "\n",
    "---\n",
    "{{$input}}\n",
    "\"\"\";\n",
    "\n",
    "var clearSyntax = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string fewShotExamples = \n",
    "        \"\"\"\n",
    "        The cafeteria has 23 apples. If they used 20 to make lunch and bought 6 more, how many do they have?\n",
    "\n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(fewShotExamples, clearSyntax);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break the task down\n",
    "> LLMs often perform better if the task is broken down into smaller step\n",
    "\n",
    "LLMs often perform better if the task is broken down into smaller steps. For example, in the search query generation prompt referenced earlier, the prompt can be restructured so that the model is first instructed to extract relevant facts, and then instructed to generate search queries that can be used to verify those facts.\n",
    "\n",
    "Notice the use of clear syntax to differentiate the sections and prime the output. In this simple example, breaking the task down from one to two steps is not very dramatic, but when trying to do this for a larger piece of text with many factual claims, breaking the task down can make a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. John Smith is married to Lucy Smith.\n",
      "2. They have five kids.\n",
      "3. He works as a software engineer at Microsoft.\n",
      "\n",
      "SEARCH QUERIES\n",
      "\n",
      "1. SEARCH(\"John Smith married to Lucy Smith\")\n",
      "2. SEARCH(\"John and Lucy Smith number of children\")\n",
      "3. SEARCH(\"John Smith software engineer at Microsoft\")\r\n"
     ]
    }
   ],
   "source": [
    "string skPrompt = \"\"\"\n",
    "You will read a paragraph, and then issue queries to a search engine in order to fact-check it. \n",
    "--- \n",
    "\n",
    "PARAGRAPH \n",
    "\n",
    "John Smith is married to Lucy Smith. They have five kids, and he works as a software engineer at Microsoft. What search queries should I do to fact-check this? \n",
    "--- \n",
    "\n",
    "{{$input}}\n",
    "\n",
    "FACTUAL CLAIMS\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "var clearSyntax = kernel.CreateSemanticFunction(skPrompt, requestSettings: new OpenAIRequestSettings { MaxTokens = 2000, Temperature = 0.0, TopP = 0.5 });\n",
    "string fewShotExamples = \n",
    "        \"\"\"\n",
    "        Now you will extract factual claims first, and then issue queries to fact-check them. When issuing a query, use the function SEARCH(\"query\") \n",
    "        \"\"\";\n",
    "var result = await kernel.RunAsync(fewShotExamples, clearSyntax);\n",
    "\n",
    "Console.WriteLine(result.GetValue<string>());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardrails\n",
    "> Provide specific instructions to limit and context to the output of completion \n",
    "\n",
    "To demonstrate this further, you can use meta-prompts / system prompts to provide guardrails to the models output. In this example here , if we ask the model what is cosmos, it replies that cosmos is open-source blockchain decentralized network. This is not the answer that we wanted. If we provide a system message in addition to the prompt, telling the model that we only want specific information on Microsoft products, we will get the answer we desire. The important thing to note here is that we are also telling the model not to discuss other topics that are not related to Microsoft. This is important to reduce hullicanations and provide the model guardrails on what it should not respond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
